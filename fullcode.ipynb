{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkDWxf5TZK6DZaKGEzNl5x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vemulaakshay12/Purchase-Recomendation-System/blob/main/fullcode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zaTILcS2D_n",
        "outputId": "9a3744c9-bf73-477a-8ae9-f11c4430a117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purchase Sequences: [['amazon', 'flipkart', 'myntra'], ['amazon', 'flipkart']]\n",
            "Tokenized Sequences: [[2, 3, 4], [2, 3]]\n",
            "Vocabulary Size: 5\n",
            "Padded Sequences: [[2 3 4]\n",
            " [2 3 0]]\n",
            "Shape of X: (2, 2)\n",
            "Shape of y: (2, 2, 5)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 2, 100)            500       \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 2, 200)            160800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 2, 200)            0         \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 2, 200)            240800    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2, 200)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2, 5)              1005      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 403105 (1.54 MB)\n",
            "Trainable params: 403105 (1.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Shape of X_train: (1, 2)\n",
            "Shape of y_train: (1, 2, 5)\n",
            "Shape of X_test: (1, 2)\n",
            "Shape of y_test: (1, 2, 5)\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 10s 10s/step - loss: 1.6078 - accuracy: 1.0000 - val_loss: 1.6072 - val_accuracy: 0.5000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.5983 - accuracy: 0.5000 - val_loss: 1.6048 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5886 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 97ms/step - loss: 1.5886 - accuracy: 1.0000 - val_loss: 1.6022 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.5827 - accuracy: 0.5000 - val_loss: 1.5997 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 1.5689 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 1.5590 - accuracy: 1.0000 - val_loss: 1.5938 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 1.5453 - accuracy: 1.0000 - val_loss: 1.5905 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 1.5270 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 1.5160 - accuracy: 1.0000 - val_loss: 1.5831 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 1.4959 - accuracy: 1.0000 - val_loss: 1.5789 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.4681 - accuracy: 1.0000 - val_loss: 1.5742 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1.4531 - accuracy: 1.0000 - val_loss: 1.5692 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1.4081 - accuracy: 1.0000 - val_loss: 1.5639 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 1.4245 - accuracy: 1.0000 - val_loss: 1.5587 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 1.3651 - accuracy: 1.0000 - val_loss: 1.5535 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 1.3193 - accuracy: 1.0000 - val_loss: 1.5487 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.2860 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 1.2182 - accuracy: 1.0000 - val_loss: 1.5426 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.1601 - accuracy: 1.0000 - val_loss: 1.5433 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.1089 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 1.0325 - accuracy: 1.0000 - val_loss: 1.5592 - val_accuracy: 0.5000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.9561 - accuracy: 1.0000 - val_loss: 1.5788 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.9069 - accuracy: 1.0000 - val_loss: 1.6106 - val_accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5426 - accuracy: 0.5000\n",
            "Test Loss: 1.542565107345581\n",
            "Test Accuracy: 0.5\n",
            "Token List for Prediction: [[3 4]]\n",
            "Predicted Indices: [[3 4]]\n",
            "Input Sequence:  ['amazon', 'flipkart', 'myntra']\n",
            "Recommendations:  ['flipkart', 'myntra']\n",
            "Token List for Prediction: [[2 3]]\n",
            "Predicted Indices: [[3 4]]\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "Token List for Prediction: [[3 4]]\n",
            "Predicted Indices: [[3 4]]\n",
            "Input Sequence: ['amazon', 'flipkart', 'myntra']\n",
            "Recommendations: ['flipkart', 'myntra']\n",
            "\n",
            "Token List for Prediction: [[2 3]]\n",
            "Predicted Indices: [[3 4]]\n",
            "Input Sequence: ['amazon', 'flipkart']\n",
            "Recommendations: ['flipkart', 'myntra']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Simulate data\n",
        "data = [\n",
        "    {'user': 'user1', 'purchases': ['amazon', 'flipkart', 'myntra']},\n",
        "    {'user': 'user2', 'purchases': ['amazon', 'flipkart']},\n",
        "    # Add more user data as needed\n",
        "]\n",
        "\n",
        "# Extract purchase sequences\n",
        "purchase_sequences = [entry['purchases'] for entry in data]\n",
        "print(\"Purchase Sequences:\", purchase_sequences)\n",
        "\n",
        "# Tokenize the purchase sequences\n",
        "tokenizer = Tokenizer(oov_token='<unk>')\n",
        "tokenizer.fit_on_texts(purchase_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(purchase_sequences)\n",
        "print(\"Tokenized Sequences:\", sequences)\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size:\", vocab_size)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = max(len(seq) for seq in sequences)\n",
        "sequences_padded = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "print(\"Padded Sequences:\", sequences_padded)\n",
        "\n",
        "# Prepare input-output pairs\n",
        "X = sequences_padded[:, :-1]\n",
        "y = sequences_padded[:, 1:]\n",
        "\n",
        "# One-hot encode the output\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_sequence_length-1))\n",
        "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Load the best model\n",
        "model.load_weights('best_model.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Function to generate recommendations for a given sequence\n",
        "def generate_recommendations(model, tokenizer, sequence, num_recommendations=5):\n",
        "    token_list = tokenizer.texts_to_sequences([sequence])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='post')\n",
        "    print(\"Token List for Prediction:\", token_list)\n",
        "    predicted_probs = model.predict(token_list, verbose=0)\n",
        "    predicted_indices = predicted_probs.argmax(axis=-1)\n",
        "    print(\"Predicted Indices:\", predicted_indices)\n",
        "    predicted_items = [tokenizer.index_word.get(idx, '<unknown>') for idx in predicted_indices[0]]\n",
        "    return predicted_items[:num_recommendations]\n",
        "\n",
        "# Example sequence from the test set\n",
        "example_sequence = purchase_sequences[0]  # replace with any test sequence\n",
        "recommendations = generate_recommendations(model, tokenizer, example_sequence)\n",
        "print(\"Input Sequence: \", example_sequence)\n",
        "print(\"Recommendations: \", recommendations)\n",
        "\n",
        "# Function to calculate metrics\n",
        "def evaluate_recommendations(model, tokenizer, X_test, y_test, num_recommendations=5):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for i in range(len(X_test)):\n",
        "        input_seq = X_test[i]\n",
        "        true_output_seq = y_test[i].argmax(axis=-1)  # get the indices of true items\n",
        "        true_items = [tokenizer.index_word.get(idx, '<unknown>') for idx in true_output_seq if idx != 0]  # exclude padding\n",
        "\n",
        "        input_items = [tokenizer.index_word.get(idx, '<unknown>') for idx in input_seq if idx != 0]  # exclude padding\n",
        "        recommendations = generate_recommendations(model, tokenizer, input_items, num_recommendations)\n",
        "\n",
        "        y_true.extend(true_items)\n",
        "        y_pred.extend(recommendations)\n",
        "\n",
        "    # Ensure y_true and y_pred have the same length\n",
        "    min_length = min(len(y_true), len(y_pred))\n",
        "    y_true = y_true[:min_length]\n",
        "    y_pred = y_pred[:min_length]\n",
        "\n",
        "    # Calculate precision, recall, and F1-score with zero_division set to handle undefined metrics\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "precision, recall, f1 = evaluate_recommendations(model, tokenizer, X_test, y_test)\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')\n",
        "\n",
        "# Generate recommendations for a few sequences and manually inspect them\n",
        "for i in range(len(purchase_sequences)):  # Adjust the range as needed\n",
        "    example_sequence = purchase_sequences[i]\n",
        "    recommendations = generate_recommendations(model, tokenizer, example_sequence)\n",
        "    print(f'Input Sequence: {example_sequence}')\n",
        "    print(f'Recommendations: {recommendations}\\n')\n"
      ]
    }
  ]
}